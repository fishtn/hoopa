# Spider
爬虫的核心，也是爬虫的入口，spider将各个功能模块组合到一起。

## 主要参数
Spider的主要参数是默认配置，子类继承Spider后，可以通过这些参数配置爬虫

- name: 爬虫名称
- worker_numbers: 最大协程数
- download_delay: 爬虫请求间隔
- pending_threshold: pending超时时间
- run_forever: 任务完成不停止, 默认False
- queue_cls: 任务队列路径，默认：const.MemoryQueue(hoopa.queues.MemoryQueue)
- clean_queue: 清空任务队列，默认False
- priority: 指定队列优先级（int，list[int]），redis优先队列有效
- downloader_cls: 下载器路径，默认：const.AiohttpDownloader(hoopa.downloader.AiohttpDownloader)
- middlewares: 下载中间件
- dupefilter_cls: 去重器路径，不配置的话根据queue_cls来决定, MemoryQueue和RabbitMQQueue使用MemoryDupeFilter，RedisQueue使用RedisDupeFilter
- clean_dupefilter: 清空去重器，默认等于clean_queue
- dupefilter_setting: 去重器设置，默认等于redis_setting
- redis_setting: redis连接配置，可以是字典，也可以是uri
- mq_uri: mq uri链接
- mq_maxsize: mq连接池大小
- mq_api_port: mq web api端口
- serialization: 序列化模块，默认ujson，可选pickle
- log_level： 日志级别，默认INFO
- log_write_file： 日志是否写入文件，默认否
- settings_path： 默认配置文件路径，默认"config.setting"。可使用全路径，如："/root/setting.py"（配置文件不可配置）
- start_urls： 起始url列表，除了url其它request参数全部默认，callback默认为parse（配置文件不可配置）


## 主要方法
- start
  - 爬虫启动入口
  - 主要参数：
    - before_start：爬虫开始前的钩子函数
    - after_stop：爬虫结束后的钩子函数
    - middleware：中间件类，`Middleware()`实例列表
    - loop：事件循环
- parse:
  - 解析函数，解析起始url，如果解析起始url，子类要实现这个函数
  - 主要参数：
    - self: 当前实例
    - request: 爬虫请求过程中的request
    - response: 下载器返回的response

- init: 负责异步函数的初始化，子类根据需要实现
  
- start_requests: 用于初始化url的一种方式
  
- process_item: 
  - 处理Item。使用redis队列会默认存储到redis（可重写），其它情况需要重写。
  - 主要参数：
    - item_list：解析函数返回的所有Item组成的list

## 使用
```python
import hoopa
from hoopa.settings import const


class DataItem(hoopa.Item):
    title: str
    type: str


class DemoSpider(hoopa.Spider):
    name = "demo"
    start_urls = ["http://httpbin.org/json"]
    downloader_cls = const.AiohttpDownloader

    async def parse(self, request, response):
        data = response.json()
        slides = data["slideshow"]["slides"]
        for slide in slides:
            data_item = DataItem()
            data_item.title = slide["title"]
            data_item.type = slide["type"]
            yield data_item

    async def process_item(self, item_list: list):
        for item in item_list:
            print(item)


if __name__ == "__main__":
    DemoSpider.start()
```